---
title: "URS"
execute: 
  echo: true
  warning: false
author: Steph, Chloe & Kate
format: html
editor: visual
---

## Questions

1.  Do humans continue to constitute the predominant host for mosquitoes?
2.  Is there more human activity closer to trail heads?
    -   Can we determine this difference in human activity through social media outlets - like alltrails.com?
3.  Does more human activity = increased mosquito density?

## Hypotheses

## Methods

### bloodmeal bioinformatics

-   of the 61 samples - 59 successfully sequenced (one failed from Upper Pine Lake)

-   one sequence result was O. virginianus (white-tailed deer) - so likely black-tail deer but must confirm white-tails do not occur in the Sierra

-   got top 5 results for each sample (if possible)

-   Identified to species those with % identity \> 98% and an e-value (error value) of \> 0

-   those ID'd as 'Canis lupus' were called to 'Canis lupus familiaris' (Dog)

-   a few samples had two species w/ the qualification called above, both were then called (mixed meal)

## Figures & Analyses

### packages

```{r}
library(tidyverse)
library(here)
library(ggsignif)
library(ggpubr)
library(lme4)
library(vegan)

install.packages("ggrepel")
library(ggrepel)
```

### data

```{r}
## concatenated data for both year (2024 & 2023) ##
# data grouped to each mosquito sampling point that was binned to the lake that was sampled
mos <- read_csv((here::here('mosquito_data.csv')))

mos_edit <- mos #editable dataframe in environment

## alltrails.com data ## 
# reviews & activities recorded in 2024 - reviews only for 2023
#min and max distance from trail head for each basin
alltrails <- read_csv((here::here('alltrails.csv')))


##2024 Data - Not Concatenated to Lake##
mos_2024 <- read_csv(
  here::here("mos_2k24.csv"))

## blood meal species IDs for 2024 ##
blood_2024 <- read_csv(
  here::here("2024_blood_ids.csv"))
```

### bloodmeal identification

```{r}
 ### Blood Meal ###
species_counts <- blood_2024 %>% 
  group_by(lake, species) %>% # group the vars by columns 'lake' and 'species'
  dplyr::summarise(count = n(), .groups="drop") # total how many time the 'species' was ID'd at each 'lake'
# then drop group_by() command - .groups = "drop

species_counts$lake <- factor(species_counts$lake, levels = c("arrowhead", "skelton", "leb", "marsh", "hidden", "heart", "flower", "matlock",
                                                      "big_mcgee", "pine", "upper_pine", "birchim", "honeymoon", 
                                                      "pioneer_1", "pioneer_2", "lower_pioneer", "tully", "cotton", 
                                                      "iw", "hortense", "elba", "moon"))

# of the 61 samples - 26 came from lake arrowhead - so separated those out for potentiall
# aiding in figure aesthetics 

arrowhead <- species_counts %>% 
  filter(lake == "arrowhead") #filtering species_counts df for any rows in 'lake' for arrowhead

wo_arrowhead <- species_counts %>% 
  filter(lake != "arrowhead") #filtering species_counts df for any rows in 'lake' without arrowhead
```

#### Figure 1: Full Data

```{r}
full <- ggplot(species_counts, aes(x = lake, y = count, fill = species)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_manual(values = c("Canis_lupus_familiaris" = "seagreen", "Homo_sapien" = "olivedrab", "Bos_taurus" = "lightgreen", "Odocoileus_hemionus" = "darkgreen"),
                    labels = c( "Canis_lupus_familiaris" = "Dog", "Homo_sapien" = "Human", "Bos_taurus" = "Cow", "Odocoileus_hemionus" = "Deer"))+
  labs(x = "Lakes", y = "Number of Detections", fill = "Species") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
    #theme(axis.text.x = element_blank()) +
  #theme(legend.position = "none")
ggsave("full_data.png", width = 6, height = 4, units = "in", dpi = 300)
```

#### Figure 2: Arrowhead Only

```{r}
ggplot(arrowhead, aes(x = lake, y = count, fill = species)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Canis_lupus_familiaris" = "peru", "Homo_sapien" = "burlywood3", "Bos_taurus" = "saddlebrown", "Odocoileus_hemionus" = "sienna3"))+
  labs(y = "Number of Detections", fill = "Species") +
  theme_classic() +
  theme(legend.position = "none")
ggsave("")
```

#### Figure 3: All Lakes Except Arrowhead

```{r}
ggplot(wo_arrowhead, aes(x = lake, y = count, fill = species)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_manual(values = c("Canis_lupus_familiaris" = "peru", "Homo_sapien" = "burlywood3", "Bos_taurus" = "saddlebrown", "Odocoileus_hemionus" = "sienna3"))+
  labs(x = "Lake", y = "Number of Detections", fill = "Species") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(axis.text.x = element_blank()) +
  theme(legend.position = "none")

```

### Human Activity by Trailhead Distance

```{r}
## for year 2024 only
alltrails$year <- as.factor(alltrails$year)

alltrails_24 <- alltrails %>% 
  filter(year == "2024")
```

```{r}
##outlier tests
z <- (alltrails_24$reviews - mean(alltrails_24$reviews)) / sd(alltrails_24$reviews)
which(abs(z) > 3)
#no outliers from z-score test

##IQR outlier test - Interquartile Range, and it’s a way to measure the spread of the middle 50% of your data can be helpful when your data isn’t normally distributed.

# Calculate IQR
iqr_val <- IQR(alltrails_24$reviews, na.rm = TRUE)

# Get Q1 and Q3
q1 <- quantile(alltrails_24$reviews, 0.25, na.rm = TRUE)
q3 <- quantile(alltrails_24$reviews, 0.75, na.rm = TRUE)

# Find outliers
outliers <- alltrails_24$reviews[alltrails_24$reviews < (q1 - 1.5 * iqr_val) |
                                   alltrails_24$reviews > (q3 + 1.5 * iqr_val)]

outliers_clean <- outliers[!is.na(outliers)]
outliers_clean 
#ok now there's more all >= 9
```

#### Figure 1

```{r}
ggplot(alltrails_24, aes(x = min_dist, y = reviews, fill = year)) +
  geom_jitter(width = 0.2, alpha = 0.5, size = 3, color = "yellowgreen") +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = "darkgreen") + 
  scale_fill_manual(values = "forestgreen") + 
  labs(x = "Minimum Trail Distance",
       y = "All Trail Reviews by Week")+
  theme_classic()+
  theme(legend.position = "none")
ggsave("human_activity.png", dpi = 650)

#1: Removed 14 rows containing non-finite outside the scale range (`stat_smooth()`). 
#2: Removed 14 rows containing missing values or values outside the scale range #(`geom_point()`).
```

#### Figure 2

```{r}
alltrails_short <- alltrails_24 %>%
  filter(reviews <= 9) #filtering out the outliers

alltrails_long <- alltrails_24 %>% 
  filter(reviews >= 10) #these are the outliers

ggplot(alltrails_short, aes(x = min_dist, y = reviews, fill = year)) +
  geom_jitter(width = 0.2, alpha = 0.5, size = 3, color = "burlywood3") +
  geom_smooth(method = "loess", se = TRUE) +
  scale_color_manual(values = "blue") +  
  scale_fill_manual(values = "lightblue") +  
  labs(x = "Minimum Trail Distance (km)",
       y = "All Trail Reviews by Week")+
  theme_classic()+
  theme(legend.position = "none")

ggplot(alltrails_long, aes(x = min_dist, y = reviews, fill = year)) +
  geom_jitter(width = 0.2, alpha = 0.4, size = 3, color = "yellowgreen") +
  geom_smooth(method = "loess", se = TRUE) +
  scale_color_manual(values = "darkgreen") +  # line colors
  scale_fill_manual(values = "forestgreen") +  # Standard Error ribbon colors
  labs(x = "Minimum Trail Distance (km)",
       y = "All Trail Reviews by Week")+
  theme_classic()+
  theme(legend.position = "none")
#you could subout the outliers but you don't have to
#warning with graph - small sample size = can't find a stable fit so rake regression line with grain of salt
```

**method = "loess"** - Loess (local polynomial regression), fits a smoother curve to the data using subsets it builds weighted least squares models for groupings of points using formula y\~x

-   you're seeing an "increase" at the 10km area of the x-axis - that's bc we didn't sample any lakes in that region so it's "estimating" based on what data we have

**method = "lm"** - Linear Model, fits a regression line to the data using formula y\~x

#### correlation test

```{r}
cor.test(alltrails$reviews, alltrails$min_dist, method = "spearman")

#Cannot compute exact p-value with ties
# - this is fine
```

**Non-parametric, Spearman's Rank Correlation Test**

-   found a significant negative correlation between reviews and minimum distance to trailhead

-   Spearman’s rho = -0.615, suggests a moderately strong negative monotonic relationship: as min_dist increases, the number of reviews tends to decrease (or vice versa)

-   p-value \< 2.2e-16 confirms the correlation is statistically significant

### Analyses of Dissimilarity

```{r}
mos_24 <- mos_edit %>% #selecting for rows only from year 2024
  mutate(date = dmy(as.character(date))) %>%
  filter(year(date) == 2024)
```

```{r}
##outlier test
z <- (mos_24$mos_min - mean(mos_24$mos_min)) / sd(mos_24$mos_min)
which(abs(z) > 3) #row 39, which is that skelton day 
```

-   usually in analysis, the outlier stays - sometimes for visualization purposes the outlier is removed to avoid graph compression and note it on the graph or in caption

```{r}
vars_24 <- mos_24 %>% 
  select(temp_max_20, hum_21,precip_tot, trail_head)
#selecting variables of interest
```

-   **NOTE: NMDs is for NUMERICAL DATA ONLY**

```{r}
vars_24 <- scale(vars_24) #centers and/or scales the columns of numeric matrices
```

-   values "closer" prevents NMDs from skewing to larger numbers

```{r}
nmds_24 <- metaMDS(vars_24, distance = "euclidean", k = 2, trymax = 100)
```

-   distance = euclidean - measurement of distance (dissimilarity between data points - rows)

-   k = 2 - two dimensional measurement, can have 3

-   try max - max time to run each simulation

```{r}
nmds_24$stress
```

-   stress = 0.09437878 - want a value \>2

```{r}
#make dataframe from nmds results
nmds_df_24 <- as.data.frame(nmds_24$points)
nmds_df_24$mos_min <- mos_24$mos_min
nmds_df_24$lake <- mos_24$lake
nmds_df_24$lake <- as.factor(nmds_df_24$lake)
```

```{r}
#fit data to nmds ordinations
fit_24 <- envfit(nmds_24, vars_24)

#extract vector coordinates from env_fit
vectors_24 <- as.data.frame(scores(fit_24, display = "vectors"))
vectors_24$label <- rownames(vectors_24)
```

#### Figure 1: vis of mos/min

```{r}

ggplot(nmds_df_24, aes(MDS1, MDS2)) +
  geom_point(aes(color = mos_min), size = 4) +
  scale_color_gradient(
    name = "mosquitoes/min",
    low = "palegreen",
    high = "darkgreen") +
  geom_segment(data = vectors_24, aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(type = "open", length = unit(0.2, "inches")), color = "black", size = 1) +   
  #geom_text(data = vectors_24, aes(x = NMDS1 + 0.05, y = NMDS2 + 0.05, label = label), 
                                       #tecolor = "black", size = 4)+
  theme_classic() 
ggsave("nmds_plot.png", dpi = )
```

#### Figure 2: still vis of mos/min points but colored by what lake they were collected from

```{r}
nmds_df_24$lake <- factor(nmds_df_24$lake, levels = c("arrowhead", "skelton", "leb", "marsh", "hidden", "heart", "flower", "matlock","big_mcgee", "pine", "upper_pine","birchim", "honeymoon", "pioneer_1", "pioneer_2", "lower_pioneer", "tully", "cotton", "iw", "hortense", "elba", "moon"))

colors1 <- c("arrowhead" = "firebrick1", "skelton" = "orangered2", "leb" = "darkorange3", "marsh" = "chocolate1", "hidden" = "darkorange1", "heart" = "orange2", "flower" = "orange", "matlock" = "goldenrod3", "big_mcgee" = "gold2", "pine" = "darkgreen", "upper_pine" = "forestgreen", "birchim" = "green3", "honeymoon" = "darkolivegreen2", "pioneer_1" = "blue3", "pioneer_2" = "dodgerblue3", "lower_pioneer" = "cadetblue3", "tully" = "purple4", "cotton" = "darkorchid3", "iw" = "mediumorchid2", "hortense" = "orchid1", "elba" = "hotpink3", "moon" = "hotpink")

ggplot(nmds_df_24, aes(MDS1, MDS2)) +
  geom_point(aes(color = lake), size = 4, show.legend = TRUE) +
  scale_color_manual(values = colors1) +
  geom_segment(data = vectors_24, aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(type = "open", length = unit(0.2, "inches")), color = "black", size = 1)+   
  #geom_text(data = vectors_24, aes(x = NMDS1 + 0.05, y = NMDS2 + 0.05, label = label), 
            #color = "black", size = 4)+ #without text
  theme_classic() +
  theme(legend.text = element_text(color = NA)) +  # hides the label text
  labs(color = NULL) +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.key.size = unit(0.4, "cm"),    # size of color boxes
    legend.text = element_blank(),        # no text labels
    legend.title = element_blank(),       # no legend title
    legend.spacing.x = unit(0.2, "cm")    # space between items
  ) +
  guides(color = guide_legend(nrow = 1))
ggsave("nmds_plot_by_lake.png", dpi = 650)
```

#### results table

```{r}
nmds_24_table <- as.data.frame(fit_24$vectors$arrows)  # Vector coordinates (directions)
nmds_24_table$r2 <- fit_24$vectors$r                   # Strength of correlation (r²)
nmds_24_table$pval <- fit_24$vectors$pvals             # Significance

# Add rownames as a column for clarity
nmds_24_table$Variable <- rownames(nmds_24_table)

# Reorder columns if you'd like
nmds_24_table <- nmds_24_table[, c("Variable", "NMDS1", "NMDS2", "r2", "pval")]
```

-   table now saved as an object in your environment

### Human Activity & Mosquitoes by Basin

```{r}
mos_24$lake <- as.factor(mos_24$lake)
mos_24$lake <- factor(mos_24$lake, levels = c("arrowhead", "skelton", "leb", "marsh", "hidden", "heart", "flower", "matlock","big_mcgee", "pine", "upper_pine", "birchim", "honeymoon", "pioneer_1", "pioneer_2", "lower_pioneer", "tully", "cotton", "iw", "hortense", "elba", "moon"))
mos_24$basin <- as.factor(mos_24$basin)
mos_24$basin <- factor(mos_24$basin, levels = c("duck", "rock", "onion", "mcgee", "pine", "mono", "fish", "french"))

mos_24 <- mos_24 %>% 
  filter(!basin == "onion")
```

#### Figure 1

```{r}
ggplot(mos_24, aes(x = basin, y = hum_21)) +
  stat_summary(fun = mean, geom = "point", color = "blue", size = 4) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), 
               geom = "errorbar", width = 0.3) +
  geom_jitter(aes(y = hum_21, color = lake), width = 0.3, alpha = 0.7, size = 3, show.legend = FALSE)+
  scale_color_manual(values = colors1)+
  theme_classic()

ggplot(mos_24, aes(x = basin, y = mos_min)) +
  stat_summary(fun = mean, geom = "point", color = "blue", size = 4) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), 
               geom = "errorbar", width = 0.3) +
  geom_jitter(aes(y = mos_min, color = lake), width = 0.3, alpha = 0.7, size = 3, show.legend = FALSE)+
  scale_color_manual(values = colors1)+
  theme_classic()
```

-   put these two side by side & note y-axis differences

#### Linear Mixed Model

```{r}
#adding ice off days column
ice_off_dates <- data.frame(
  lake = c("arrowhead", "skelton", "leb", "marsh", "heart", "hidden", "big_mcgee", "pine", "upper_pine", "birchim", 
           "honeymoon", "tully", "cotton", "iw", "hortense", "elba", "moon"),
  date = c("2024-06-06", "2024-06-06", "2024-05-24", "2024-05-22", "2024-06-01",
           "2024-05-23", "2024-06-19", "2024-05-25", "2024-05-31", "2024-05-31",
           "2024-06-07", "2024-06-17", "2024-06-19", "2024-06-15", "2024-06-17", 
           "2024-06-12", "2024-06-14"
))
ice_off_dates <- ice_off_dates %>% 
  mutate(date = ymd(date))

mos_24 <- mos_24 %>%
  left_join(ice_off_dates, by = "lake") %>%
  rename(
    ice_off_date = date.y,
    date_sampled = date.x
  )

mos_24 <- mos_24 %>% 
  filter(!basin == "onion")

mos_24 <- mos_24 %>% 
  mutate(since_ice_off = as.numeric(date_sampled - ice_off_date))
```

```{r}
# take log of human activity
mos_24 <- mos_24 %>% 
  mutate(log_hum_21 = log(hum_21))
```

```{r}
#best LMM
m2 <- mos_24 %>% 
  filter(is.finite(log_hum_21), is.finite(mos_min)) %>% 
  lmer(mos_min ~ log_hum_21 + since_ice_off + (1 | basin), data = .)
summary(m2)
```

**REML criterion at convergence: 136.4**

-   goodness-of-fit metric used to compare models (lower = better fit, all else equal)

**Residuals**

-   The max residual is a bit large (3.58), probably due to the outlier. Others look fine - they should all be around 0.0

**Random Effects:**

-   model accounts for different basins having different average levels of the response

-   residual variance is variance not explained by basin-level differences

[**Fixed Effects: what you're actually interested in**]{.underline}

-   intercept = mean outcome when predictors are = to 0

<!-- -->

-   human activity = for every unit increase in log(human activity), mosquitoes per minute density increases on average \~0.82, when holding other variables constant

-   days since ice off date = for each day since ice off the mosquito per minute density decreases on average 0.079 when holding other variables constant

**Correlation of Fixed Effects:**

-   moderate, so nothing of concern

```{r}
library(lmerTest)
#p-values
m2_test <- mos_24 %>% 
  filter(is.finite(log_hum_21), is.finite(mos_min)) %>% 
  lmer(mos_min ~ log_hum_21 + since_ice_off + (1 | basin), data = .)
summary(m2_test)
```

[**Fixed Effects with P-values: (ignore other outputs)**]{.underline}

-   intercept: not significant - in this case result is NULL to us since we're not interested in what happens when the fixed effects are 0

-   human activity = marginally significant at the 0.1 threshold but not the conventional 0.05 cutoff

```         
-   Can say we think its "trending significant" but low sample size & we think with more sampling you'd see a significance. You can back this up with the correlation test (significant) and the blood results.

    -   LMM is not the best model for this data which also probably effects result
```

-   ice off = statistically significant - strong evidence that days since ice-off -\> decline in mosquito density

[**T-value vs. p-value: similar, but not the same**]{.underline}

-   t-value: measures how many standard errors your estimated effect is away from 0 (null hypothesis)

-   p-value: is the probability of observing the t-value as extreme as the one you got [if]{.underline} the null hypothesis is true. A.k.a. how likely the result happened by chance.

p-value is calculated from the t-value and the degrees of freedom (inverse relationship)

So think of the t-value as the [raw score]{.underline} and the p-value as the [percentile of that score]{.underline}. A high t-value means your result is more extreme, and the p-value tells you how rare that level of extremeness is under the null.

[**Marginal and Conditional R\^2**]{.underline}

```{r}
#r^2 results
library(performance)
r2(m2_test)
```

-   [**Marginal R\^2**]{.underline} = proportion of variance explained [by fixed effects only]{.underline}

-   [**Conditional R\^2**]{.underline} = proportion of variance explained [by the entire model (including random effects)]{.underline}

-   [**Fixed effects explain 20.2%**]{.underline} of the variation in mosquito density

-   [**Full model explains 31.8%**]{.underline} of the variation in mosquito density - so basin-level difference do matter and including the random effect helps the model fit better

    -   **How I view R\^2 results**

        -   0-10%: ok your model is wrong, you were wrong, all of the above?

        -   11-30%: "eh..." you're on to something for sure

        -   31-50%: nice job! evidence is there supporting you

        -   51-70%: woohoo!

        -   70%-above: back to your model is wrong, you did something wrong, OR you should publish this shit in *Nature*

#### Figure 2

```{r}
mos_24_z <- mos_24 %>% 
  dplyr::slice(-37)
#remove outlier

ggplot(mos_24_z, aes(x = log_hum_21)) +
  geom_jitter(aes(y = mos_min, color = lake), width = 0.3, alpha = 0.7, size = 3, show.legend = FALSE) +
  geom_smooth(aes(y = mos_min), method = "lm", se = TRUE, fill = "lightblue", color = "blue") +
  scale_color_manual(values = colors1) +
  theme_classic() +
  labs(x = "log(Human Activity totaled every 21 Days)", y = "Mosquitoes per Minute")
#Removed 7 rows containing non-finite outside the scale range (`stat_smooth()`). 
```

-   interlay this to graph above?

```{r}
#model predicted mosquito densities v. human activity
library(ggeffects)

plot_data <- ggpredict(m2_test, terms = "log_hum_21")
plot(plot_data) + 
  theme_classic() +
  labs(y = "Predicted Mosquitoes per Minute",
       x = "log(Human Activity totaled every 21 days)")
```

#### OR Spearman's Rank Test

```{r}
cor.test(mos_24$hum_21, mos_24$mos_min, method = "spearman")
#Cannot compute exact p-value with ties
# - this is fine
```

p-value = 0.009997, rho = 0.3886961

-   indicates a moderate positive monotonic relationship between human activity and mos density

-   statistically significant, meaning there is strong evidence that the observed relationship is not due to chance
